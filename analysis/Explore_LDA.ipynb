{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys         \n",
    "sys.path.append('/home/pranisaa/working_dir/Text-Summarization')\n",
    "from config import *\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from dataset import Dataset\n",
    "from transformers import T5Tokenizer, BartTokenizer\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranisaa/thesis/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beau</th>\n",
       "      <th>deep</th>\n",
       "      <th>fabby</th>\n",
       "      <th>learning</th>\n",
       "      <th>love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>my name is beau</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my name is fabby</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i love deep learning</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      beau     deep  fabby  learning     love\n",
       "my name is beau        1.0  0.00000    0.0   0.00000  0.00000\n",
       "my name is fabby       0.0  0.00000    1.0   0.00000  0.00000\n",
       "i love deep learning   0.0  0.57735    0.0   0.57735  0.57735"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "text_tfidf = ['my name is beau', 'my name is fabby', 'i love deep learning']\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', use_idf=True) #use_idf bool, default=True (to highlight by comparison) Enable inverse-document-frequency reweighting\n",
    "x = tfidf_vectorizer.fit_transform(text_tfidf)\n",
    "print(x.toarray().shape)\n",
    "# print(tfidf_vectorizer.get_feature_names().shape)\n",
    "#         tfidfcounts = pd.DataFrame(x.toarray(),index = tfidf_vectorizer.get_feature_names(), columns = [\"tfidf\"])\n",
    "tfidfcounts = pd.DataFrame(x.toarray(),index = text_tfidf,  columns = tfidf_vectorizer.get_feature_names())\n",
    "tfidfcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/pranisaa/.cache/huggingface/modules/datasets_modules/datasets/xsum/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934 (last modified on Wed Jan 19 12:12:25 2022) since it couldn't be found locally at xsum., or remotely on the Hugging Face Hub.\n",
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/pranisaa/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9717e771aba40c9a4ed8714ee031d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = 'xsum'\n",
    "\n",
    "if data == 'cnn_dailymail':\n",
    "    dataset = load_dataset(data, '3.0.0')\n",
    "    source_text = \"article\"\n",
    "    target_text = \"highlights\"\n",
    "elif data == \"xsum\":\n",
    "    dataset = load_dataset(data)\n",
    "    source_text = \"document\"\n",
    "    target_text = \"summary\"\n",
    "else:\n",
    "    raise ValueError(\"Undefined dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 204045\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 11332\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 11334\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('max_512_q1.pkl', 'rb') as handle:\n",
    "#     b = pickle.load(handle)\n",
    "    \n",
    "pickle_in = open(\"val_len_q1_max512.pickle\",\"rb\")\n",
    "example_dict = pickle.load(pickle_in)\n",
    "q1_id = example_dict['ids']\n",
    "\n",
    "pickle_in = open(\"val_len_q3_max512.pickle\",\"rb\")\n",
    "example_dict = pickle.load(pickle_in)\n",
    "q3_id = example_dict['ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # path = f\"\"\"../model/{model_params[\"MODEL\"]}_{data}_lenrestriction_30epoch\"\"\"\n",
    "# # path_df = os.path.join(path, f\"\"\"result_eval/predictions_{model_params[\"MODEL\"]}_epoch{model_params[\"TRAIN_EPOCHS\"]-1}.csv\"\"\")\n",
    "# path_df = 'max_512_q1.csv'\n",
    "# df = pd.read_csv(path_df, reset_index = False)\n",
    "# df_dict = df.to_dict()\n",
    "# # q1_id = df_dict['q1']['ids']\n",
    "# # q3_id = df_dict['q3']['ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = {'id': dataset['validation']['id'], 'document': dataset['validation']['document']}\n",
    "df_data = pd.DataFrame.from_dict(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(doc_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_val_q1 = []\n",
    "doc_idex_q1 = []\n",
    "for i in range(len(df_data['id'])):\n",
    "    if int(df_data['id'][i]) in list(q1_id):\n",
    "        doc_val_q1.append(df_data['document'][i])\n",
    "        doc_idex_q1.append(df_data['id'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_val_q3 = []\n",
    "doc_idex_q3 = []\n",
    "for i in range(len(df_data['id'])):\n",
    "    if int(df_data['id'][i]) in list(q3_id):\n",
    "#         print(df_data['id'][i])\n",
    "        doc_val_q3.append(df_data['document'][i])\n",
    "        doc_idex_q3.append(df_data['id'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'38295789'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "print(len(doc_val_q1))\n",
    "print(len(doc_idex_q3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "# from bs4 import BeautifulSoup\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02041554, 0.91834519, 0.02039711, 0.02039324, 0.02044891],\n",
       "       [0.03109351, 0.03136772, 0.87511378, 0.03116803, 0.03125696],\n",
       "       [0.03295945, 0.03296886, 0.86810711, 0.03298163, 0.03298296],\n",
       "       [0.0239644 , 0.02404003, 0.02396178, 0.90401879, 0.024015  ],\n",
       "       [0.02162763, 0.02167016, 0.02159751, 0.02165304, 0.91345166],\n",
       "       [0.02993633, 0.02995392, 0.02994845, 0.03005026, 0.88011104],\n",
       "       [0.02557655, 0.0255959 , 0.02558839, 0.02557978, 0.89765938],\n",
       "       [0.02461403, 0.02468917, 0.024617  , 0.90137548, 0.02470432],\n",
       "       [0.86091347, 0.03480663, 0.03472497, 0.03472278, 0.03483215],\n",
       "       [0.02187807, 0.02189361, 0.02188416, 0.91239307, 0.02195109],\n",
       "       [0.01902714, 0.92376041, 0.01902471, 0.01908914, 0.0190986 ],\n",
       "       [0.03218625, 0.0321807 , 0.03215722, 0.03217095, 0.87130488],\n",
       "       [0.03191388, 0.87207729, 0.03208414, 0.03192203, 0.03200266],\n",
       "       [0.02913857, 0.88343734, 0.02912897, 0.02914299, 0.02915212],\n",
       "       [0.01836757, 0.01843153, 0.018374  , 0.92643508, 0.01839182],\n",
       "       [0.02386589, 0.02391821, 0.02387091, 0.02387592, 0.90446906],\n",
       "       [0.02124273, 0.91507613, 0.02122338, 0.02120255, 0.0212552 ],\n",
       "       [0.91023186, 0.0224823 , 0.02243154, 0.02237281, 0.0224815 ],\n",
       "       [0.02086038, 0.02090299, 0.02089241, 0.91641127, 0.02093295],\n",
       "       [0.03621931, 0.03636382, 0.03622228, 0.03638778, 0.85480681],\n",
       "       [0.02434891, 0.90256679, 0.02430869, 0.02433921, 0.0244364 ],\n",
       "       [0.02848031, 0.88603645, 0.02849861, 0.02851722, 0.02846742],\n",
       "       [0.02029114, 0.02031944, 0.02030231, 0.02028121, 0.9188059 ],\n",
       "       [0.91446584, 0.02136836, 0.02141128, 0.02137628, 0.02137824],\n",
       "       [0.01831165, 0.01831317, 0.01831015, 0.92670816, 0.01835687],\n",
       "       [0.02325619, 0.90679916, 0.02332609, 0.02330787, 0.02331068],\n",
       "       [0.02123766, 0.02126678, 0.02121283, 0.02126738, 0.91501535],\n",
       "       [0.02278975, 0.02288955, 0.90864442, 0.02280827, 0.022868  ],\n",
       "       [0.01906079, 0.01907437, 0.01908633, 0.92363942, 0.0191391 ],\n",
       "       [0.03097684, 0.03099347, 0.87599457, 0.03101433, 0.0310208 ],\n",
       "       [0.02823483, 0.0282559 , 0.02824881, 0.02848699, 0.88677348],\n",
       "       [0.02092664, 0.02096648, 0.02084716, 0.91631763, 0.0209421 ],\n",
       "       [0.02397653, 0.02391902, 0.02384101, 0.02385801, 0.90440542],\n",
       "       [0.02553593, 0.02552287, 0.89761269, 0.02554032, 0.02578819],\n",
       "       [0.0506292 , 0.05055832, 0.7976348 , 0.05059685, 0.05058082],\n",
       "       [0.02097457, 0.02103978, 0.91598531, 0.02098675, 0.0210136 ],\n",
       "       [0.06720345, 0.06711332, 0.06772871, 0.06719158, 0.73076293],\n",
       "       [0.02064453, 0.02063284, 0.91755197, 0.02057628, 0.02059437],\n",
       "       [0.02267105, 0.02278809, 0.02276576, 0.02269299, 0.9090821 ],\n",
       "       [0.0243539 , 0.02439482, 0.02435535, 0.9024929 , 0.02440302],\n",
       "       [0.03229069, 0.03234112, 0.03236877, 0.87062084, 0.03237859],\n",
       "       [0.02213174, 0.91135288, 0.02210194, 0.0221515 , 0.02226193],\n",
       "       [0.01874335, 0.01873231, 0.01873362, 0.92500934, 0.01878138],\n",
       "       [0.02061324, 0.02063135, 0.02064513, 0.91743546, 0.02067482],\n",
       "       [0.03200069, 0.03203569, 0.8718201 , 0.03204577, 0.03209775],\n",
       "       [0.85764848, 0.03552264, 0.03552098, 0.03560619, 0.03570171],\n",
       "       [0.02236508, 0.02252063, 0.9102432 , 0.02238519, 0.0224859 ],\n",
       "       [0.91099758, 0.02227812, 0.02223484, 0.02224934, 0.02224013],\n",
       "       [0.01988945, 0.01996475, 0.01992093, 0.01991893, 0.92030594],\n",
       "       [0.90027154, 0.02496876, 0.0249232 , 0.02489849, 0.02493801],\n",
       "       [0.02700841, 0.02699699, 0.02695703, 0.02700005, 0.89203751],\n",
       "       [0.02254534, 0.02257671, 0.90943049, 0.02278077, 0.02266669],\n",
       "       [0.02190878, 0.02196648, 0.91217228, 0.02201205, 0.0219404 ],\n",
       "       [0.02346566, 0.02348063, 0.02343262, 0.02348448, 0.90613661],\n",
       "       [0.02690313, 0.02692284, 0.02686873, 0.02689355, 0.89241174],\n",
       "       [0.92713873, 0.01820246, 0.01821644, 0.01819218, 0.0182502 ],\n",
       "       [0.91148406, 0.0221423 , 0.02210464, 0.02211385, 0.02215514],\n",
       "       [0.02040373, 0.02037881, 0.02042845, 0.91839406, 0.02039496],\n",
       "       [0.02345403, 0.02343879, 0.02348739, 0.90609997, 0.02351982],\n",
       "       [0.02299793, 0.90813977, 0.02292603, 0.0229551 , 0.02298117],\n",
       "       [0.02175535, 0.02178032, 0.91300957, 0.02170185, 0.02175291],\n",
       "       [0.02768352, 0.0277889 , 0.88906366, 0.02768359, 0.02778033],\n",
       "       [0.88004652, 0.03003472, 0.02994486, 0.02995281, 0.0300211 ],\n",
       "       [0.02225101, 0.91090652, 0.02225639, 0.02231236, 0.02227372],\n",
       "       [0.03338198, 0.86642437, 0.03337576, 0.0333948 , 0.03342309],\n",
       "       [0.02170543, 0.91303957, 0.02173039, 0.02175292, 0.02177169],\n",
       "       [0.02020067, 0.91924136, 0.02020258, 0.02013724, 0.02021815],\n",
       "       [0.86356239, 0.03405743, 0.03419266, 0.0340685 , 0.03411902],\n",
       "       [0.02665266, 0.02669242, 0.89331651, 0.02664726, 0.02669115],\n",
       "       [0.02857092, 0.02858794, 0.02858386, 0.02854623, 0.88571105],\n",
       "       [0.01850245, 0.92574139, 0.01858142, 0.01852775, 0.01864698],\n",
       "       [0.02413359, 0.90341136, 0.02413821, 0.02413415, 0.0241827 ],\n",
       "       [0.02146082, 0.02153052, 0.0214922 , 0.02151084, 0.91400561],\n",
       "       [0.02103505, 0.02106364, 0.02104688, 0.9156912 , 0.02116323],\n",
       "       [0.02523855, 0.02526767, 0.02525824, 0.02531864, 0.8989169 ],\n",
       "       [0.9296334 , 0.01758827, 0.01757818, 0.01760149, 0.01759865],\n",
       "       [0.02045506, 0.02053166, 0.02041299, 0.02049158, 0.91810871],\n",
       "       [0.02997854, 0.87987737, 0.03005749, 0.03002433, 0.03006227],\n",
       "       [0.01995908, 0.02000693, 0.9200504 , 0.01998519, 0.01999841],\n",
       "       [0.01954309, 0.01949182, 0.92197534, 0.01946048, 0.01952927],\n",
       "       [0.8818976 , 0.02955431, 0.02952497, 0.02951989, 0.02950323],\n",
       "       [0.01949331, 0.01950337, 0.0195027 , 0.9220207 , 0.01947992],\n",
       "       [0.9080665 , 0.02297269, 0.02295272, 0.0229413 , 0.02306679],\n",
       "       [0.02138179, 0.91432243, 0.02140625, 0.02139188, 0.02149764],\n",
       "       [0.02044128, 0.02047393, 0.02043925, 0.02043981, 0.91820572],\n",
       "       [0.02242445, 0.0224834 , 0.0224904 , 0.02244645, 0.9101553 ],\n",
       "       [0.01925264, 0.01924365, 0.01926238, 0.01927682, 0.92296451],\n",
       "       [0.022463  , 0.02249959, 0.02249161, 0.02251875, 0.91002705],\n",
       "       [0.02266752, 0.90927172, 0.02266929, 0.02271605, 0.02267542],\n",
       "       [0.02382543, 0.02393472, 0.02380621, 0.90449869, 0.02393494],\n",
       "       [0.03248622, 0.86955367, 0.03264553, 0.03261934, 0.03269524],\n",
       "       [0.02008103, 0.91957146, 0.02006994, 0.0201392 , 0.02013836],\n",
       "       [0.9246622 , 0.01881912, 0.01880115, 0.01888016, 0.01883738],\n",
       "       [0.92217178, 0.01946051, 0.01943631, 0.0194536 , 0.01947781],\n",
       "       [0.02225157, 0.02237145, 0.02226647, 0.91083444, 0.02227607],\n",
       "       [0.01870058, 0.92508568, 0.01870955, 0.01873284, 0.01877136],\n",
       "       [0.02695225, 0.02697708, 0.02695934, 0.02695891, 0.89215242],\n",
       "       [0.91375208, 0.0215827 , 0.02152009, 0.02161705, 0.02152808],\n",
       "       [0.02395597, 0.02391827, 0.02392458, 0.02402461, 0.90417657],\n",
       "       [0.03043687, 0.03056673, 0.03043867, 0.03049295, 0.87806478]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer = TfidfVectorizer(stop_words='english', max_features=50000)\n",
    "gps_news_matrix = tf_vectorizer.fit_transform(doc_val_q1)\n",
    "lda = LatentDirichletAllocation(n_components=5, learning_method='online', random_state=0, verbose=0, n_jobs = -1)\n",
    "lda_model = lda.fit(gps_news_matrix)\n",
    "lda_matrix = lda_model.transform(gps_news_matrix)\n",
    "lda_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found via LDA:\n",
      "\n",
      "Topic #0:\n",
      "defender tree harzi scotland said incident nuclear enclosure larne bank cycling barcelona british branches korea\n",
      "\n",
      "Topic #1:\n",
      "said police year court ireland scottish mr world paul rescue king time season special league\n",
      "\n",
      "Topic #2:\n",
      "said river bbc people hoard club bridge coins mr apple armagh bristol fish local city\n",
      "\n",
      "Topic #3:\n",
      "said police government mr park year people turkey asylum information mining smith years security inquiry\n",
      "\n",
      "Topic #4:\n",
      "said police called man box baby year pub road games family time pronounced death property\n"
     ]
    }
   ],
   "source": [
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = tf_vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "      \n",
    "        print(\"\\nTopic #%d:\" % topic_idx )\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA:\")\n",
    "print_topics(lda_model, gps_news_matrix, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0:\n",
      "mr year ms duffy said hilary death brunner schwartzel people yellen sharif police woman hiv\n",
      "\n",
      "Topic #1:\n",
      "said year coin water play going staff rmt mr bailey flanagan stations season tuesday told\n",
      "\n",
      "Topic #2:\n",
      "said car bruno people saw yorkshire movie like hrw head space scenery wildlife terry half\n",
      "\n",
      "Topic #3:\n",
      "shares year said rose oil shortman minutes scotland students clyde film 11 dunbartonshire seminary cyber\n",
      "\n",
      "Topic #4:\n",
      "mr said device points playback city supported media james amateur just work place irving pemberton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranisaa/thesis/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print_topics(lda_model, gps_news_matrix, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranisaa/thesis/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 101 nearest neighbors...\n",
      "[t-SNE] Indexed 102 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 102 samples in 0.005s...\n",
      "[t-SNE] Computed conditional probabilities for sample 102 / 102\n",
      "[t-SNE] Mean sigma: 0.783573\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 47.897194\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.020470\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [106]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lda_matrix\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTSNE1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTSNE2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT-SNE plot of different headlines ( headlines are clustered among their topics)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(n_components=2, perplexity=50, learning_rate=100, \n",
    "                        n_iter=1000, verbose=1, random_state=0, angle=0.75)\n",
    "tsne_features = model.fit_transform(lda_matrix)\n",
    "df = pd.DataFrame(tsne_features)\n",
    "df['topic'] = lda_matrix.argmax(axis=1)\n",
    "df.columns = ['TSNE1', 'TSNE2', 'topic']\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title('T-SNE plot of different headlines ( headlines are clustered among their topics)')\n",
    "ax = sns.scatterplot(x = 'TSNE1', y = 'TSNE2', hue = 'topic', data = df, legend = 'full')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training set len:  204045\n",
      "Final data set len:  34007\n"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "    \"MODEL\": \"bart-base\",  # model_type: t5-base/t5-large\n",
    "    \"BATCH_SIZE\": 1,  # training batch size\n",
    "    \"MAX_SOURCE_TEXT_LENGTH\": 512,  # max length of source text\n",
    "    \"MAX_TARGET_TEXT_LENGTH\": 36,  # max length of target text\n",
    "    \"SEED\": 42,  # set seed for reproducibility\n",
    "}\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "print(\"Total training set len: \", len(train_dataset))\n",
    "\n",
    "# Define portion due to RAM limitation\n",
    "portion = 6\n",
    "tfidf_data_size = len(train_dataset)//portion\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(f'facebook/{model_params[\"MODEL\"]}') # just because our Dataset requires it\n",
    "training_set = Dataset(\n",
    "    train_dataset[: tfidf_data_size],\n",
    "    tokenizer,\n",
    "    model_params[\"MODEL\"],\n",
    "    model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
    "    model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
    "    source_text,\n",
    "    target_text,\n",
    ")\n",
    "print(\"Final data set len: \", len(training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranisaa/thesis/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_tfidf = training_set.compute_tfidf()\n",
    "df_tfidf_mean = df_tfidf.mean(axis=0).nlargest(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "said           0.037405\n",
       "mr             0.019586\n",
       "year           0.016670\n",
       "people         0.015084\n",
       "police         0.015080\n",
       "                 ...   \n",
       "development    0.002504\n",
       "growth         0.002499\n",
       "performance    0.002498\n",
       "michael        0.002498\n",
       "issues         0.002492\n",
       "Length: 500, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_mask_list = []\n",
    "for i,v in enumerate(df_tfidf_mean):\n",
    "#     print(df_tfidf_mean.index[i])\n",
    "#     print(v)\n",
    "    to_mask_list.append(df_tfidf_mean.index[i])\n",
    "#     print(df_tfidf_mean.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_mask_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "nouns = []\n",
    "verbs = []\n",
    "adjs = []\n",
    "advs = []\n",
    "cardinals = []\n",
    "others = []\n",
    "for word in to_mask_list:\n",
    "  \n",
    "    # returns a document of object\n",
    "    tag = nlp(word)\n",
    "    if \"NN\" in tag[0].tag_ :\n",
    "        nouns.append(word)\n",
    "    elif \"VB\" in tag[0].tag_ :\n",
    "        verbs.append(word)\n",
    "    elif \"JJ\" in tag[0].tag_ :\n",
    "        adjs.append(word)\n",
    "    elif \"RB\" in tag[0].tag_ :\n",
    "        advs.append(word)\n",
    "    elif \"CD\" in tag[0].tag_ :\n",
    "        cardinals.append(word)\n",
    "    else:\n",
    "        others.append((word,tag[0].tag_))\n",
    "#     # checking if it is a noun or not\n",
    "#     if(tag[0].tag_ == 'NNP'):\n",
    "#         print(text, \" is a noun.\")\n",
    "# else:\n",
    "#     print(text, \" is not a noun.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of nouns:  276\n",
      "len of verbs:  117\n",
      "len of adjs:  52\n",
      "len of others:  6\n"
     ]
    }
   ],
   "source": [
    "print(\"len of nouns: \", len(nouns))\n",
    "print(\"len of verbs: \", len(verbs))\n",
    "print(\"len of adjs: \", len(adjs))\n",
    "print(\"len of others: \", len(others))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy Tag\n",
    "'''\n",
    "    \".\": \"punctuation mark, sentence closer\",\n",
    "    \",\": \"punctuation mark, comma\",\n",
    "    \"-LRB-\": \"left round bracket\",\n",
    "    \"-RRB-\": \"right round bracket\",\n",
    "    \"``\": \"opening quotation mark\",\n",
    "    '\"\"': \"closing quotation mark\",\n",
    "    \"''\": \"closing quotation mark\",\n",
    "    \":\": \"punctuation mark, colon or ellipsis\",\n",
    "    \"$\": \"symbol, currency\",\n",
    "    \"#\": \"symbol, number sign\",\n",
    "    \"AFX\": \"affix\",\n",
    "    \"CC\": \"conjunction, coordinating\",\n",
    "    \"CD\": \"cardinal number\",\n",
    "    \"DT\": \"determiner\",\n",
    "    \"EX\": \"existential there\",\n",
    "    \"FW\": \"foreign word\",\n",
    "    \"HYPH\": \"punctuation mark, hyphen\",\n",
    "    \"IN\": \"conjunction, subordinating or preposition\",\n",
    "    \"JJ\": \"adjective (English), other noun-modifier (Chinese)\",\n",
    "    \"JJR\": \"adjective, comparative\",\n",
    "    \"JJS\": \"adjective, superlative\",\n",
    "    \"LS\": \"list item marker\",\n",
    "    \"MD\": \"verb, modal auxiliary\",\n",
    "    \"NIL\": \"missing tag\",\n",
    "    \"NN\": \"noun, singular or mass\",\n",
    "    \"NNP\": \"noun, proper singular\",\n",
    "    \"NNPS\": \"noun, proper plural\",\n",
    "    \"NNS\": \"noun, plural\",\n",
    "    \"PDT\": \"predeterminer\",\n",
    "    \"POS\": \"possessive ending\",\n",
    "    \"PRP\": \"pronoun, personal\",\n",
    "    \"PRP$\": \"pronoun, possessive\",\n",
    "    \"RB\": \"adverb\",\n",
    "    \"RBR\": \"adverb, comparative\",\n",
    "    \"RBS\": \"adverb, superlative\",\n",
    "    \"RP\": \"adverb, particle\",\n",
    "    \"TO\": 'infinitival \"to\"',\n",
    "    \"UH\": \"interjection\",\n",
    "    \"VB\": \"verb, base form\",\n",
    "    \"VBD\": \"verb, past tense\",\n",
    "    \"VBG\": \"verb, gerund or present participle\",\n",
    "    \"VBN\": \"verb, past participle\",\n",
    "    \"VBP\": \"verb, non-3rd person singular present\",\n",
    "    \"VBZ\": \"verb, 3rd person singular present\",\n",
    "    \"WDT\": \"wh-determiner\",\n",
    "    \"WP\": \"wh-pronoun, personal\",\n",
    "    \"WP$\": \"wh-pronoun, possessive\",\n",
    "    \"WRB\": \"wh-adverb\",\n",
    "    \"SP\": \"space (English), sentence-final particle (Chinese)\",\n",
    "    \"ADD\": \"email\",\n",
    "    \"NFP\": \"superfluous punctuation\",\n",
    "    \"GW\": \"additional word in multi-word expression\",\n",
    "    \"XX\": \"unknown\",\n",
    "    \"BES\": 'auxiliary \"be\"',\n",
    "    \"HVS\": 'forms of \"have\"',\n",
    "    \"_SP\": \"whitespace\",\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"to_mask_list_top500\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(to_mask_list, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5-small xsum\n",
    "- get samples with low rouge scores\n",
    "- get samples with high rouge scores\n",
    "- tf-idf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

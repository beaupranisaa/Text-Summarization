{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"datalength/train_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>ids</th>\n",
       "      <th>doc text</th>\n",
       "      <th>target text</th>\n",
       "      <th>doc len</th>\n",
       "      <th>sum len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35232142</td>\n",
       "      <td>summarize: The full cost of damage in Newton S...</td>\n",
       "      <td>Clean-up operations are continuing across the ...</td>\n",
       "      <td>541</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40143035</td>\n",
       "      <td>summarize: A fire alarm went off at the Holida...</td>\n",
       "      <td>Two tourist buses have been destroyed by fire ...</td>\n",
       "      <td>194</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>35951548</td>\n",
       "      <td>summarize: Ferrari appeared in a position to c...</td>\n",
       "      <td>Lewis Hamilton stormed to pole position at the...</td>\n",
       "      <td>1214</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>36266422</td>\n",
       "      <td>summarize: John Edward Bates, formerly of Spal...</td>\n",
       "      <td>A former Lincolnshire Police officer carried o...</td>\n",
       "      <td>369</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>38826984</td>\n",
       "      <td>summarize: Patients and staff were evacuated f...</td>\n",
       "      <td>An armed man who locked himself into a room at...</td>\n",
       "      <td>242</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index       ids  \\\n",
       "0           0      0  35232142   \n",
       "1           1      1  40143035   \n",
       "2           2      2  35951548   \n",
       "3           3      3  36266422   \n",
       "4           4      4  38826984   \n",
       "\n",
       "                                            doc text  \\\n",
       "0  summarize: The full cost of damage in Newton S...   \n",
       "1  summarize: A fire alarm went off at the Holida...   \n",
       "2  summarize: Ferrari appeared in a position to c...   \n",
       "3  summarize: John Edward Bates, formerly of Spal...   \n",
       "4  summarize: Patients and staff were evacuated f...   \n",
       "\n",
       "                                         target text  doc len  sum len  \n",
       "0  Clean-up operations are continuing across the ...      541       28  \n",
       "1  Two tourist buses have been destroyed by fire ...      194       21  \n",
       "2  Lewis Hamilton stormed to pole position at the...     1214       24  \n",
       "3  A former Lincolnshire Police officer carried o...      369       30  \n",
       "4  An armed man who locked himself into a room at...      242       35  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4795\n"
     ]
    }
   ],
   "source": [
    "cond1 = df['doc len'] <= 512\n",
    "cond2 = df['doc len'] >= 485\n",
    "cond3 = df['sum len'] <= 36\n",
    "df_filtered = df[cond1 & cond2 & cond3].reset_index()\n",
    "print(len(df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e44ee97f77040439b42ca2825993d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 12:30:46 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "========================\n",
      "\n",
      "2022-04-27 12:30:46 INFO: Use device: gpu\n",
      "2022-04-27 12:30:46 INFO: Loading: tokenize\n",
      "2022-04-27 12:30:46 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize')\n",
    "tok_doc = {\"doc text\": []}\n",
    "tok_summ = {\"target text\": []}\n",
    "for n in range(len(df_filtered['doc text'])):\n",
    "    doc = nlp(df_filtered['doc text'][n][11:])\n",
    "    summ = nlp(df_filtered['target text'][n])\n",
    "    tokenized_doc = [sentence.text for sentence in doc.sentences]\n",
    "#     tokenized_doc = ['\\t'.join(tokenized_doc)]\n",
    "    tokenized_summ = [sentence.text for sentence in summ.sentences]\n",
    "    tok_doc['doc text'].append(tokenized_doc)\n",
    "    tok_summ['target text'].append(tokenized_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(tok_doc, orient='index')\n",
    "df.to_csv('test', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [99]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(csvfilename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m output_file:\n\u001b[1;32m      5\u001b[0m     dict_writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictWriter(output_file, tok_doc\u001b[38;5;241m.\u001b[39mkeys(), delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mdict_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriteheader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     dict_writer\u001b[38;5;241m.\u001b[39mwriterows(tok_doc)\n",
      "File \u001b[0;32m/usr/lib/python3.8/csv.py:143\u001b[0m, in \u001b[0;36mDictWriter.writeheader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwriteheader\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    142\u001b[0m     header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfieldnames, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfieldnames))\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/csv.py:154\u001b[0m, in \u001b[0;36mDictWriter.writerow\u001b[0;34m(self, rowdict)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwriterow\u001b[39m(\u001b[38;5;28mself\u001b[39m, rowdict):\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dict_to_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrowdict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import csv\n",
    "csvfilename = ('CSVFile.csv')\n",
    "with open(csvfilename, 'wb') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, tok_doc.keys(), delimiter='\\t')\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(tok_doc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_line = '\\t'.join(article_sents) + '\\n'\n",
    "      f_art.write(article_line.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('articles.tsv', 'wb') as f_art:\n",
    "    for doc in tok_doc['doc text']:\n",
    "        article_line = '\\t'.join(doc) + '\\n'\n",
    "        f_art.write(article_line.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('summaries.tsv', 'wb') as f_art:\n",
    "    for doc in tok_summ['target text']:\n",
    "        article_line = '\\t'.join(doc) + '\\n'\n",
    "        f_art.write(article_line.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('summaries.tsv', 'wb') as f_sum:\n",
    "    for doc in tok_summ['target text']:\n",
    "        for sent in doc: \n",
    "            sum_line = '\\t'.join(sent) + '\\n'\n",
    "        f_sum.write(sum_line.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('summaries.tsv', 'w') as file:\n",
    "    for doc in tok_summ['target text']:\n",
    "        for sent in doc:\n",
    "             file.write(sent + '\\t')\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('articles.tsv', 'w') as file:\n",
    "    for doc in tok_doc['doc text']:\n",
    "        for sent in doc:\n",
    "             file.write(sent + '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
